{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dgmfa2j58kdelh2cfurfmv",
    "execution_id": "4a2b4f60-5e9d-4043-86cf-d7cfce3a744c"
   },
   "source": [
    "### Oganyan Robert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ct4drxo9s3fk2ny978okoh",
    "execution_id": "b0b8c389-43be-4ca0-8621-161e4a52252b"
   },
   "source": [
    "Если Вы не против, я некоторые вещи в домашнем задании переписал так, как хотел / как меня учили в ШАДе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "e2orwfg840hbcl5pm8m34",
    "execution_id": "a3a0eebc-e660-4e09-9361-5854f5c4817d",
    "id": "RPcfHT5C-mKZ"
   },
   "source": [
    "# HW1: seq2seq nmt\n",
    "\n",
    "**Homework Goals**\n",
    "\n",
    "1. Get familiar with text data preparation\n",
    "2. Learn to work with RNN\n",
    "3. Train the model to translate `en-->ru`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "p99klsmrh7lys22s8gujg",
    "id": "0hUc8aEg8S2_"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "g1yc1ycmg7ibk4vg0u6ok6",
    "execution_id": "52a062ba-4366-48d2-859d-87270ea60b6a",
    "id": "qdM5tBYV8S3J"
   },
   "source": [
    "## Naive way of texts representation:\n",
    "\n",
    "0. Normalize spelling\n",
    "1. Filter out all special characters\n",
    "2. Split by spaces, do *naive tokenization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "t21vfhvkaugghxlcnmg2rc",
    "id": "qSYbvPOW8S3L"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269ff7cb684340628e20e0f8565d209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=336666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAW alphabet 174 symbols: \n",
      " !\"$%&'()+,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz «°º»ãçéêîïóöúǘЁАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёׁ​–—―‘’… ‽₂€№\n",
      "After preprocessing 62 symbols:   !,.?abcdefghijklmnopqrstuvwxyzабвгдежзиклмнопрстуфхцчшщъыьэюя\n",
      "There are 336666 pairs\n",
      "[['go .', 'иди .'], ['go .', 'идите .'], ['hi .', 'здравствуите .'], ['hi .', 'привет !'], ['hi .', 'хаи .']]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Prepare data and look at it\n",
    "# In addition to the dictionary, we are also interested in a set of characters\n",
    "raw_alphabet = set()\n",
    "alphabet = set()\n",
    "def normalize(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess(s):\n",
    "    raw_alphabet.update(s)\n",
    "    s = normalize(s.lower().strip())\n",
    "    s = re.sub(r\"[^a-zа-я?.,!]+\", \" \", s)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    alphabet.update(s)\n",
    "    return s\n",
    "\n",
    "pairs = []\n",
    "with open('eng-rus.txt', 'r') as fin:\n",
    "    for line in tqdm(fin.readlines()):\n",
    "        pair = [preprocess(_) for _ in line.split('\\t')]\n",
    "        pairs.append(pair)\n",
    "        \n",
    "print(\"RAW alphabet {} symbols:\".format(len(raw_alphabet)), \n",
    "      \"\".join(sorted(raw_alphabet)))\n",
    "print(\"After preprocessing {} symbols: \".format(len(alphabet)), \n",
    "      \"\".join(sorted(alphabet)))\n",
    "print(\"There are {} pairs\".format(len(pairs)))\n",
    "print(pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "z40i3hnlm4r1slqxma4i1n",
    "execution_id": "3f7ef84e-4cf8-45e7-854e-b430e419c06f",
    "id": "h9ARXr6b8S3U"
   },
   "source": [
    "Each word will be assigned a number + we will need special tokens for the beginning and end of the sequence and for unknown words.\n",
    "`<SOS>, <EOS>, <UNK>`\n",
    "\n",
    "We have two languages, to work with each we need functions for translating from words to numbers and vice versa.\n",
    "\n",
    "It is proposed to implement these functions as dictionaries. Allocate the first 4 numbers for special tokens\n",
    "\n",
    "**(1 point)** Implement the dictionary building function, the function takes a list of strings (normalized sentences, can be splited by spaces) as input. Organize the dictionary in a reasonable way so that rare words can be thrown out if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "quorakzwdymtl713niohlh",
    "id": "2epLOt_-8S3V"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "COMMON_TOKENS = ['PAD', 'SOS', 'EOS', 'UNK']\n",
    "\n",
    "def build_vocabs(sents, max_size=1000):\n",
    "    vocab = Counter()\n",
    "    for sent in sents:\n",
    "        vocab.update(sent.split())\n",
    "        \n",
    "    vocab = sorted(vocab.items(),  key = lambda item: item[1], reverse=True)\n",
    "    len_of_vocab = max_size - len(COMMON_TOKENS)\n",
    "    vocab = [word[0] for word in vocab[:len_of_vocab]]\n",
    "    \n",
    "    vocab = COMMON_TOKENS + vocab\n",
    "    \n",
    "    tok2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2tok = {idx: word for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "eng, rus = list(zip(*pairs))\n",
    "rus2idx, idx2rus = build_vocabs(rus, max_size=10000)\n",
    "eng2idx, idx2eng = build_vocabs(eng, max_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "vi7lo2re93najb7az9q147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 5000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(rus2idx), len(idx2rus), len(eng2idx), len(idx2eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "amklg3bke9c971gwrghwb",
    "id": "xh5koecS8S3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2539, 1264, 83, 2]\n",
      "SOS привет мир ! EOS\n",
      "[1, 1960, 439, 174, 2]\n",
      "SOS hello world ! EOS\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "def sentence2idx(s, tok2idx):\n",
    "    tokens = preprocess(s).split(' ')\n",
    "    unk = tok2idx['UNK']\n",
    "    return [tok2idx['SOS']] + [tok2idx.get(_, unk) for _ in tokens] + [tok2idx['EOS']]\n",
    "\n",
    "\n",
    "def idx2sentence(s, idx2tok):\n",
    "    return \" \".join(idx2tok[_] for _ in s)\n",
    "\n",
    "# check the consistency of the transformations\n",
    "x = sentence2idx('Привет мир!', rus2idx)\n",
    "print(x)\n",
    "print(idx2sentence(x, idx2rus))\n",
    "\n",
    "x = sentence2idx('Hello world!', eng2idx)\n",
    "print(x)\n",
    "print(idx2sentence(x, idx2eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xxj04lrw2h8rgzgi8dvvvm",
    "execution_id": "6161fa2a-77ef-42ab-93ca-22d50300ad45",
    "id": "Dhjjx52i8S3g"
   },
   "source": [
    "## Dealing with arbitrary length sequences in pytorch\n",
    "\n",
    "We need to be able to generate batches of `[bs, 1, seq_len]` tensors.\n",
    "But in our dataset, the samples are of different lengths:\n",
    "\n",
    "- we could cut everything down to the minimum length\n",
    "- padd to maximum length\n",
    "- choose some average length\n",
    "\n",
    "**(1 point)** Split the dataset on train and validate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "phvk4ir9onfzn47exp5fi",
    "execution_id": "1a1ce2c1-477f-46d5-b5e4-4650439cc960"
   },
   "source": [
    "Ниже представлена версия датасета, где внутри делается паддинг к одинаковому размеру. Таким образом, мы можем прокликать ячейку с наивным даталоадером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "7d4fg5i0duuvya1de5g5s"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d95e89dbdf49a58c9489dd5ba0a785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=336666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# make a dataset with encoded pairs:\n",
    "class EngRusDataset(Dataset):\n",
    "    def __init__(self, pairs, max_len=None, pad=eng2idx['PAD']):\n",
    "        \n",
    "        # same len for every sentence\n",
    "        self.max_len = max_len or max(max(map(len, [x[0] for x in pairs])), max(map(len, [x[1] for x in pairs])))\n",
    "        \n",
    "        self.pairs = np.full([len(pairs), 2, self.max_len], pad, dtype=np.int64)\n",
    "        for i in range(len(pairs)):\n",
    "            eng_padded = pairs[i][0][:self.max_len]\n",
    "            rus_padded = pairs[i][1][:self.max_len]\n",
    "            self.pairs[i, 0, :len(eng_padded)] = eng_padded\n",
    "            self.pairs[i, 1, :len(rus_padded)] = rus_padded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        eng, rus = self.pairs[item]\n",
    "        return dict(\n",
    "            eng=eng,\n",
    "            rus=rus,\n",
    "        )\n",
    "\n",
    "encoded = []\n",
    "for eng, rus in tqdm(pairs):\n",
    "    a = sentence2idx(eng, eng2idx)\n",
    "    b = sentence2idx(rus, rus2idx)\n",
    "    encoded.append((a, b))\n",
    "\n",
    "    \n",
    "train_data, val_data = train_test_split(encoded, train_size=0.8, random_state=42, shuffle=True)\n",
    "trainset = EngRusDataset(train_data, max_len=15)\n",
    "valset = EngRusDataset(val_data, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "a2n2xakx426z17lt9iq1lh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    5,   22,   11,   36,    8,  377,    3,    4,    2,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   19, 1132,   66,   44, 1546,    3,    4,    2,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   56,   39,   11,    7,   47,    3,    9,    2,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   26,   60,  163,  152,  207,  103, 1390,    3,    4,    2,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   19,  106,   11,   33, 1475,    3,    4,    2,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,    6,   59,   85,   92,  740,   21,   44,  251,    3,    4,    2,\n",
       "            0,    0,    0],\n",
       "        [   1,   23,   38,    6,   15,  399,    3,    9,    2,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,    7,   72,    8,  111,   12,  672,    3,    4,    2,    0,    0,\n",
       "            0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True)\n",
    "it = iter(trainloader)\n",
    "batch = next(it)['eng']\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zfj04izgp8a80qknffs6hg",
    "execution_id": "cae4e150-fb94-480b-8f75-52a67799370b"
   },
   "source": [
    "Однако в беседе мы обсудили, что идеалогически здесь делать паддинг вроде как неверно, поэтому не будем менять код в датасете, будем делать паддинг в collate. Соответственно Датасет остается без изменений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "o91zw69epe0fdwkp74wcep",
    "id": "kmGX7wtL8S3i"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9701c42f447d47979c5cbde7b017aba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=336666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "# make a dataset with encoded pairs:\n",
    "class EngRusDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        eng, rus = self.pairs[item]\n",
    "        return dict(\n",
    "            eng=eng,\n",
    "            rus=rus,\n",
    "        )\n",
    "\n",
    "encoded = []\n",
    "for eng, rus in tqdm(pairs):\n",
    "    a = sentence2idx(eng, eng2idx)\n",
    "    b = sentence2idx(rus, rus2idx)\n",
    "    encoded.append((a, b))\n",
    "\n",
    "    \n",
    "train_data, val_data = train_test_split(encoded, train_size=0.8, random_state=42, shuffle=True)\n",
    "trainset = EngRusDataset(train_data)\n",
    "valset = EngRusDataset(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wnwn410eac291i7x9lhn",
    "execution_id": "d8520aab-547b-4246-ba13-5745ea0c24b7",
    "id": "9PDpAtEq8S3n"
   },
   "source": [
    "Let's build a naive DataLoader and check how it makes batches:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zawrf45v86swf8cbsmb2",
    "execution_id": "d675d7cd-24f7-47c6-a11e-617591728ce7",
    "id": "O7blZtcq8S3w"
   },
   "source": [
    "In my case, the result was:\n",
    "```\n",
    "[tensor([1, 1, 1, 1, 1, 1, 1, 1]),\n",
    " tensor([ 6,  7,  6, 15,  5,  6,  5, 62]),\n",
    " tensor([ 48,  34,  83,   7,  32, 221,  22,  43]),\n",
    " tensor([  5, 143,  37,  36, 129,  12,  11,  66]),\n",
    " tensor([  73, 1258,  279,    8,    6,  555,   41,   10]),\n",
    " tensor([  8, 140,   8, 628,  20,  96,  13, 270]),\n",
    " tensor([  47,    4,   15,   18,   55,  269,    6, 1287]),\n",
    " tensor([ 58,   2,  13, 140, 193, 140, 171, 140])]\n",
    "```\n",
    "\n",
    "What's weird here?\n",
    "1. This is not a tensor, but a list of tensors. Accordingly, when iterating over zero dimension (`batch[i, :]`), we will get not an i-example, but i-tokens for all examples in the batch. This is not a problem, but different from the expected behavior.\n",
    "2. Only one example ends with `<EOS>` (2), the others are cut off to match its length. And this is a problem.\n",
    "\n",
    "We would like to padd all examples to the maximum length in the batch.\n",
    "But at the stage of preparing the example (in the `__getitem__` function), we do not know the batch neighbors!\n",
    "In order to change the batch merging logic, we need to write our own `collate_fn` function in the DataLoader constructor:\n",
    "\n",
    "```\n",
    "def collate_fn(samples):\n",
    "    # samples -- list of dictionaries samples\n",
    "    <...>\n",
    "    return batch\n",
    "```\n",
    "\n",
    "**(1 point)** Write a `collate_fn` function that padds _correctly_ rus and eng sequences and merges them into batches, where `batch[i, :]` returns the tokens for the `i` example.\n",
    "\n",
    "Expected output (for a sequence with left padding):\n",
    "\n",
    "```\n",
    "tensor([[   1,   10, 3429,  405,  113,  676,   10, 1031,  140,    4,    2],\n",
    "        [   0,    1,   57,   18,   23,   19,   61,    7,  140,    4,    2],\n",
    "        [   0,    0,    0,    1,   16,   17, 1131,  416,  140,    4,    2],\n",
    "        [   0,    0,    0,    1,   13,  465,   75,  197,  140,    4,    2],\n",
    "        [   0,    0,    0,    1,    6,  302,   13,  144,  140,    4,    2],\n",
    "        [   0,    1,    6,   59,  205,  167,    8,   15,  140,    4,    2],\n",
    "        [   0,    0,    0,    0,    1,    6,   14,  678,  140,    4,    2],\n",
    "        [   0,    0,    1,    5,   29,   67,    6,   14,  140,    4,    2]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "su8tb7yvhujahajir1cfrk",
    "execution_id": "c9ef87b5-6300-476e-821f-417bac9790d6"
   },
   "source": [
    "Чтобы длина предложения в батче была одинаковой надо сделать паддинг. Буду добавлять PAD справа. Одинаковая длина предложений либо задается вручную, либо считается как максимальная длина закодированного предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "p9y3bx4occkf6u00fa6hk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 48, 50, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "max(map(len, [x[0] for x in train_data])), max(map(len, [x[1] for x in train_data])), max(map(len, [x[0] for x in val_data])), max(map(len, [x[1] for x in val_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dohlj7sda2nxqawm81i40r",
    "execution_id": "7b98a563-6ca0-4695-acbb-ec7c728f9071"
   },
   "source": [
    "Максимальные размеры слишком большие. Будем задавать фиксированную длину maxlen равную, например, 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "co19ffrobo5jwsq0v09z3p",
    "execution_id": "5a9ef7c7-c206-4965-a077-812ff0493149"
   },
   "source": [
    "*Заметка для будущего меня:* функтор получился немного костыльным. Я решил попробовать сделать через pad_to_sequence. Есть проблема: Если заданная максимальная длина больше, чем длина максимального по длине предложения, то он не будет паддить предложения к максимальной длине. Решение: добавить \"мусорный\" тензор заданной максимальной длины, а в конце, после паддингов, удалить его. Also Весь этот код можно переписать и сделать удобно через простой torch.full(), по аналогии первой версии датасета, но мне интересно было попробовать по-другому"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "42v43y6zykt0u9peuwfkteh",
    "id": "SMSeFFHQ8S3y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    6,  134,   11,  411,  119,    3,    4,    2,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   62,   34, 1555,    3,    4,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,    5,  140,  548,   31, 1290,  172,    3,    4,    2,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,    6,  165,   44, 2025,  423,  935,    3,    4,    2,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1, 1098,  183,   12,  819,    3,    4,    2,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   1,   52, 1633,    5,  108,    6,   20, 3641,  137,  582,    5, 1432,\n",
       "           19,   20,    2],\n",
       "        [   1,   25,   98,   57,  244,   50,    8,  894, 1548,    3,    4,    2,\n",
       "            0,    0,    0],\n",
       "        [   1,    6,   20,  546,    3,    4,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "class CollateFnEngRus():\n",
    "    def __init__(self, max_len=None, pad=eng2idx['PAD']):\n",
    "        self.pad = pad\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        data = dict(\n",
    "            eng=list(),\n",
    "            rus=list()\n",
    "        )\n",
    "        max_len = self.max_len or max(max(map(len, [x for x in batch['eng']])), max(map(len, [x for x in batch['rus']])))\n",
    "        \n",
    "        # Костыль, чтобы предложения паддились к максимальной длине\n",
    "        data[\"eng\"].append(torch.full((max_len,), fill_value=0))\n",
    "        data[\"rus\"].append(torch.full((max_len,), fill_value=0))\n",
    "        \n",
    "        for sentence in batch:\n",
    "            eng, rus = torch.tensor(sentence['eng'], dtype=torch.int), torch.tensor(sentence['rus'], dtype=torch.int)\n",
    "            eng[min(max_len - 1, len(eng) - 1)] = eng2idx['EOS']\n",
    "            rus[min(max_len - 1, len(rus) - 1)] = rus2idx['EOS']\n",
    "            data[\"eng\"].append(eng[:max_len])\n",
    "            data[\"rus\"].append(rus[:max_len])\n",
    "        \n",
    "        data = {lang: pad_sequence(sentences, batch_first=True, padding_value=self.pad)[1:] for lang, sentences in data.items()}\n",
    "        return data\n",
    "    \n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=CollateFnEngRus(max_len=15))\n",
    "it = iter(trainloader)\n",
    "next(it)['eng']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9vfgtd3mkdvqbgvc3s3srk",
    "execution_id": "c6b7581e-c287-4754-ae49-65a0631091b3",
    "id": "vDcGAXiA-mKm"
   },
   "source": [
    "Now we have the correct data generator, and all we have to do is write the model (encoder and decoder).\n",
    "\n",
    "\n",
    "### Encoder\n",
    "\n",
    "The input tensor contains integers and has dimensions `[bs, seq_len]`,\n",
    "\n",
    "We will pass them through the layer with embeddings and get the tensor `[bs, seq_len, dim]`. Now we have floating point numbers that can be fed to RNN layers as input.\n",
    "\n",
    "\n",
    "\n",
    "GRU is an RNN with a specific structure:\n",
    "<img src=\"https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png\">\n",
    "\n",
    "In the picture, the yellow rectangles are the line layers with the corresponding activation functions.\n",
    "\n",
    "\n",
    "`nn.RNN` allows you to create and use multi-layer one- and two-way layers as one layer.\n",
    "All parameters must be specified during creation, and then simply applied during the forward pass.\n",
    "\n",
    "\n",
    "The order of dimensions is a bit different from the usual in convolutional networks, this is due to the inability to parallel recurrent calculations effectively.\n",
    "\n",
    "\n",
    "**batch_first=True**\n",
    "\n",
    "Such an RNN layer expects two tensors as input:\n",
    "  - input with sizes `[bs, seq_len, dim]`,\n",
    "  - hidden_state with dimensions `[num_layers * num_directions, bs, hidden_size]`.\n",
    " \n",
    " \n",
    "The output is two tensors:\n",
    "- output `[bs, seq_len, dim]`,\n",
    "- hidden `[num_layers * num_directions, bs, hidden]`.\n",
    "\n",
    "We will apply RNN in two ways:\n",
    "- to the entire sequence, to translate the entire phrase in one language into one vector (EncoderRNN)\n",
    "- to one tensor and input token to generate a phrase in another language (DecoderRNN)\n",
    "\n",
    "\n",
    "We will put the entire input sequence into a hidden state vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9bydbghwuzdtvs8feqa9to",
    "execution_id": "d0363fdf-3df3-4480-b1f6-4670d00bba38"
   },
   "source": [
    "Немного переписал. Теперь Энкодер возвращает только последний скрытый слой, который идет к энкодеру на вход (по правде говоря, этот скрытый слой пропущен еще и через дополнительный линейный слой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "ku1ifu4b1i7l1a7hlasyi",
    "id": "dph7rI9_8S33"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size, emb_size=64):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = 1\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True, num_layers=self.num_layers)\n",
    "        self.dec_start = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        batch_size = inp.shape[0]\n",
    "        inp_emb = self.embeddings(inp)\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.rnn(inp_emb, hidden)\n",
    "        # enc_seq: [batch, len_of_sequence, hid_size], last_state: [batch, hid_size]\n",
    "        \n",
    "        # note: last_state is not _actually_ last because of padding, let's find the real last_state\n",
    "        lengths = ((inp != eng2idx['EOS']) & (inp != eng2idx['PAD'])).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 2)\n",
    "        last_state = enc_seq[torch.arange(batch_size), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "        \n",
    "        dec_start = self.dec_start(last_state)\n",
    "        return [dec_start]\n",
    "    \n",
    "    def init_hidden(self, batch_size=1, device=None):\n",
    "        # be aware about dimension! https://pytorch.org/docs/stable/nn.html#torch.nn.GRU\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "wd7ho6cje3jyxt6lrzgsqp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 15])\n",
      "torch.Size([8, 256])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "enc = EncoderRNN(vocab_size=len(eng2idx), hidden_size=256, emb_size=256)\n",
    "x = next(it)['eng']\n",
    "print(x.shape)\n",
    "hidden = enc.init_hidden(8)\n",
    "hidden_to_dec = enc(x, hidden)\n",
    "print(hidden_to_dec[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "q592ecj8soa2i00lre1rck",
    "execution_id": "0b3f7414-726d-43fc-b6e6-d1a5f0cd56fc",
    "id": "Vg6cvr8L-mKm"
   },
   "source": [
    "We want the decoder to generate a translation for us -- a sequence of tokens from another language, using the encoder's hidden state vector.\n",
    "\n",
    "To do this, we will supply hidden and `<SOS>`token to the input.\n",
    "At each step, the decoder will return hidden and output vector.\n",
    "Output vector is the probability distribution for the next token (respectively, it has the size of the output language dictionary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ca1nq1cwihbrezkf5eco8",
    "execution_id": "81d89665-aa48-435e-9c48-d593b4544ee6"
   },
   "source": [
    "Декодер принимает батч предложений, пускает их по слову через GruCell, скрытый слой подается еще раз в GRU, а также он, пропущенный через линейный слой, возвращается нам в качестве логитов. В классе DecoderRNN написан функционал для обучения, но не предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "g1q91xjndj6gduce2ehea",
    "id": "oYfecQb88S38"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, emb_size=64):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)      \n",
    "        self.rnn = nn.GRUCell(emb_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def decode_step(self, prev_state, prev_tokens):\n",
    "        prev_gru0_state = prev_state[0]\n",
    "        \n",
    "        prev_embs = self.embeddings(prev_tokens)\n",
    "        next_gru0_state = self.rnn(prev_embs, prev_gru0_state)\n",
    "        new_dec_state = [next_gru0_state]\n",
    "        output_logits = self.out(next_gru0_state)\n",
    "        \n",
    "        return new_dec_state, output_logits\n",
    "    \n",
    "    \n",
    "    def forward(self, initial_state, out_tokens):\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "        \n",
    "        # initial logits: always predict SOS\n",
    "        onehot_bos = F.one_hot(torch.full([batch_size], rus2idx['SOS'], dtype=torch.int64),\n",
    "                               num_classes=self.vocab_size).to(device=device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "        \n",
    "        logits_sequence = [first_logits]\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            state, logits = self.decode_step(state, out_tokens[:, i])\n",
    "            logits_sequence.append(logits.to(device=device))\n",
    "        return torch.stack(logits_sequence, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "x4w20tgttgnvvviplokihd",
    "id": "oyMwF94n8S3_"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dec = DecoderRNN(len(rus2idx), 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7r6pxz24vemn4akh56bs4l",
    "execution_id": "1553e82c-cfc4-4d84-8d53-fc64c2e38f12",
    "id": "a_Vj3_PB-mKn"
   },
   "source": [
    "Let's get a tensor with tokens of size `[bs, seq_len]` from the data generator and try to iterate over seq_len to generate the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "gkmvwdsmc0a6sgl40slv7p",
    "id": "wVFcg0Uz8S4C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 15]) torch.Size([8, 15])\n",
      "torch.Size([8, 15, 10000])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "it = iter(trainloader)\n",
    "batch = next(it) # get batch\n",
    "batch, y = batch['rus'], batch['eng']\n",
    "print(batch.shape, y.shape)\n",
    "bs, seq_len = batch.shape\n",
    "output = dec(hidden_to_dec, batch)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wtb83b84vqdfhitxjx8d",
    "execution_id": "c075b061-e34f-4355-8839-84f84255329e",
    "id": "ECBleoB4F58E"
   },
   "source": [
    "**(6 points)** Fill in a training part and train the encoder and decoder.\n",
    "\n",
    "1. You need to write getting the next token (integer) from the distribution: a vector of size `len(rus2idx)`. Since we are working in batches, this should be a batchified operation. You have several options for how to do this:\n",
    " - take by argmax\n",
    " - sample from distribution (torch.multinomial)\n",
    " - during training, take tokens from ground truth (and this must be done at least sometimes so that the model converges).\n",
    " \n",
    "2. You need to write a loss calculation. It is convenient to do this at each step: after the `<EOS>` occurs in the example, you do not need to count the loss for it (in the vectorized version, you can multiply the loss for `<PAD>`-tokens by zero - this is called masking). Loss is simply the sum of cross-entropy losses for each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vybcmnya2xkxpa6c11zjb",
    "execution_id": "5b00a605-20b7-4f2f-b5d2-42ee5f640047"
   },
   "source": [
    "Функция для предсказания seq2seq модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "cellId": "hm5762cafhap9lhoqz34o"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def predict(model, inp_lines,batch_size = BATCH_SIZE, max_len=100):\n",
    "    encoder, decoder = model\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    def decode_inference(initial_state, batch_size = batch_size, max_len=max_len):\n",
    "        batch_size = len(initial_state[0])\n",
    "        state = initial_state\n",
    "        \n",
    "        # We genrate SOS at first\n",
    "        outputs = [torch.full([batch_size], rus2idx['SOS'], dtype=torch.int64, \n",
    "                              device=device)]\n",
    "        all_states = [initial_state]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            state, logits = decoder.decode_step(state, outputs[-1])\n",
    "            outputs.append(logits.argmax(dim=-1)) # Probably should do beam search instead\n",
    "            all_states.append(state)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "    hid = encoder.init_hidden(batch_size).to(device=device)\n",
    "    initial_state = encoder(inp_lines, hid)\n",
    "    out_ids, states = decode_inference(initial_state, batch_size, max_len)\n",
    "    return out_ids.cpu().numpy(), states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xtdt8vqyxlaz7q0dzyf39",
    "execution_id": "0c16e296-d6fc-4d67-ba23-f0d547500011"
   },
   "source": [
    "Качество полученной модели будем мерить с помощью метрики BLEU на валидации. Machine translation is commonly evaluated with BLEU score. This metric simply computes which fraction of predicted n-grams is actually present in the reference translation. It does so for n=1,2,3 and 4 and computes the geometric average with penalty if translation is shorter than reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cellId": "nh5mlckjry2ojhlyixhm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def compute_bleu(translations, actual):\n",
    "    return corpus_bleu(\n",
    "        [[idx2sentence(ref.detach().cpu().numpy(), idx2rus).split()] for ref in actual],\n",
    "        [idx2sentence(trans, idx2rus).split() for trans in translations],\n",
    "        smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
    "        ) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "o06gjc3ebvg32pdk40dkr9",
    "execution_id": "792bcac7-85e1-4792-a777-5fe5e41b2385"
   },
   "source": [
    "Маска при подсчете лосса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "rktq6gvastn6khoup7jrp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def compute_mask(sentences, lang2idx):\n",
    "    return sentences != lang2idx['PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "cellId": "1tcth7vdeq6g120q5bhold",
    "id": "EshFSblS-mKn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "def train_test_model(model, optimizer, dataloader, val_loader, epoches_cnt = 5): \n",
    "    encoder, decoder = model\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    logs = defaultdict(list)\n",
    "    \n",
    "    step = 0\n",
    "    for _ in trange(epoches_cnt):\n",
    "        for batch in tqdm(dataloader):\n",
    "            rus = batch['rus'].to(device)\n",
    "            eng = batch['eng'].to(device)\n",
    "\n",
    "            # Computing loss:\n",
    "            mask = compute_mask(rus, rus2idx) # [batch_size, out_len]\n",
    "            targets_1hot = F.one_hot(rus, len(rus2idx)).to(torch.float32)\n",
    "            \n",
    "            cur_batch_size = batch['rus'].shape[0]\n",
    "            encoder_hidden = encoder.init_hidden(cur_batch_size).to(device)\n",
    "            \n",
    "            hidden_to_dec = encoder(eng, encoder_hidden)\n",
    "            \n",
    "            \n",
    "            logits_seq = decoder(hidden_to_dec, rus) # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "            logprobs_seq = nn.LogSoftmax(dim=-1)(logits_seq)\n",
    "            \n",
    "            logp_out = (logprobs_seq * targets_1hot).sum(dim=-1) # log-probabilities of correct outputs, [batch_size, out_len]\n",
    "            # ^-- this will select the probability of the actual next token.\n",
    "\n",
    "            lengths = mask.sum()\n",
    "\n",
    "            # average cross-entropy over tokens where mask == True\n",
    "            mask_loss = torch.sum(logp_out * mask)\n",
    "            loss = - mask_loss / lengths\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            logs['loss'].append(loss.item())\n",
    "            \n",
    "            # Validation\n",
    "            if step % 100 == 0:\n",
    "                logs['bleu'].append((step, validate(model, val_loader)))\n",
    "                encoder.train()\n",
    "                decoder.train()\n",
    "\n",
    "            step+=1            \n",
    "    print('Last loss:', logs['loss'][-1])\n",
    "    return logs\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        scores = []\n",
    "        for batch in dataloader:\n",
    "            \n",
    "            y_true = batch['rus']\n",
    "            y_pred, _ = predict(model, batch['eng'].to(device=device), batch_size = batch['eng'].shape[0], max_len=SEQ_LEN)\n",
    "            scores.append(compute_bleu(y_pred, y_true))\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    \n",
    "def plot_logs(logs):\n",
    "    clear_output()\n",
    "    plt.figure()\n",
    "    plt.plot(logs['loss'], zorder=1)\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('steps')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(*zip(*logs['bleu']), zorder=1)\n",
    "    plt.title('Validation Bleu')\n",
    "    plt.xlabel('steps')\n",
    "    plt.grid()    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "cellId": "vno30ax9udhnn1leoed2md",
    "id": "ThQj4uOx8S4P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c8c4de1d7444895d999e7fcfd7a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [03:00<03:00, 180.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abb5a5c01e04a408b26e5557917a17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [06:02<00:00, 181.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.9346079230308533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 256\n",
    "SEQ_LEN = 15\n",
    "encoder = EncoderRNN(vocab_size=len(eng2idx), hidden_size=256, emb_size=256)\n",
    "decoder = DecoderRNN(vocab_size=len(rus2idx), hidden_size=256, emb_size=256)\n",
    "\n",
    "opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=5e-3)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=CollateFnEngRus(SEQ_LEN))\n",
    "valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=CollateFnEngRus(SEQ_LEN))\n",
    "model = (encoder, decoder)\n",
    "\n",
    "\n",
    "logs = train_test_model(model, opt, trainloader, valloader, epoches_cnt=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "cellId": "b04aht2byloq2md6rlrjuo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "plot_logs(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "cellId": "d437c9g7k4k1tstq78965e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  SOS do you miss your friends UNK ? EOS PAD PAD PAD PAD PAD PAD\n",
      "Actual: SOS вы скучаете по своим друзьям UNK ? EOS PAD PAD PAD PAD PAD PAD\n",
      "Predicted: SOS скучаешь по подругами UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS\n",
      "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "Source:  SOS tom is still too young to understand that UNK . EOS PAD PAD PAD\n",
      "Actual: SOS том еще слишком мал, чтобы это понять UNK . EOS PAD PAD PAD PAD\n",
      "Predicted: SOS том все еще слишком молод, чтобы получать это UNK . EOS UNK . EOS UNK\n",
      "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "Source:  SOS forgive me if i have offended you UNK . EOS PAD PAD PAD PAD\n",
      "Actual: SOS простите, если обидел UNK . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Predicted: SOS прости, что я тебя беспокоюсь UNK . EOS UNK . EOS UNK . EOS UNK\n",
      "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n",
      "Source:  SOS i don t want to see anyone today UNK . EOS PAD PAD PAD\n",
      "Actual: SOS я не хочу сегодня никого видеть UNK . EOS PAD PAD PAD PAD PAD\n",
      "Predicted: SOS я не хочу сегодня кто нибудь увидеть UNK . EOS UNK . EOS UNK .\n",
      "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "valloader2 = DataLoader(valset, batch_size=4, shuffle=True, collate_fn=CollateFnEngRus(SEQ_LEN))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "model = (encoder, decoder)\n",
    "with torch.no_grad():\n",
    "    for batch in valloader2:\n",
    "        y_true = batch['rus']\n",
    "        y_pred, _ = predict(model, batch['eng'].to(device=device), batch_size = batch['eng'].shape[0], max_len=SEQ_LEN)\n",
    "\n",
    "        for i in range(4):\n",
    "            print('Source: ', idx2sentence(batch['eng'][i].detach().cpu().numpy(), idx2eng))\n",
    "            print('Actual:', idx2sentence(batch['rus'][i].detach().cpu().numpy(), idx2rus))\n",
    "            print('Predicted:', idx2sentence(y_pred[i], idx2rus))\n",
    "            print('+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4hikhhqjgzmgspaaigj846",
    "execution_id": "71f611b3-35b0-4b7b-9421-956c5416b613"
   },
   "source": [
    "Мы сильно улучшили bleu и на глаз получили достаточно качественный перевод!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "svsyfggc3pxyfyp2cupj",
    "execution_id": "a282a115-cfd8-4b2c-9c27-96476019ab45",
    "id": "R8G9EoojGDdJ"
   },
   "source": [
    "**(2 points)** Write a translation function with sampling from a distribution with temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zu5phhsw60kwiaxjwe50yg",
    "execution_id": "49fa401c-4bdd-461e-b12f-dd226b1477a5"
   },
   "source": [
    "Хорошие модели машинного перевода (и языковые модели) должны обладать двумя свойствами: conherancy и diversity.\n",
    "conherancy - сгенерированный текст должен иметь смысл. diversity - модель должна генерировать различные сэмплы. \n",
    "\n",
    "Добиться этого можно с помощью выбора не argmax логита, а выбрать случайный логит с взвешенными вероятностями. Однако у нас вполне может быть так, что один логит может быть сильно выше других, и поэтому он будет выбираться намного чаще других. Чтобы это исправить, делают сэмплинг с *температурой*, т.е делят логиты на какой-то гиперпараметр. Чем ниже температура, тем больше будет разница между максимальным логитом и оставшимися. Тем самым мы максимизируем критерий conherancy, но минимизируем diversity. Чем выше температура - тем более равномерными будут логиты. Теперь уже мы максимизируем diversity, но уменьшаем conherancy. В случае сэмплинга с температурой важно подобрать температуру так, чтобы соблюдался баланс этих двух критериев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "cellId": "b6sptr8j37rpraep1akqhh",
    "id": "64h3_w528S4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 23, 14, 63, 46, 9, 2]\n",
      "What is going on?\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS EOS UNK ? EOS UNK ? EOS UNK ? EOS\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS чем сеичас UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что будет потом UNK ? EOS UNK ? EOS UNK ? EOS UNK . EOS\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS EOS\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS ко\n",
      "SOS что будет продолжаться UNK ? EOS UNK ? EOS UNK ? EOS EOS UNK ?\n",
      "SOS что будете на UNK UNK ? EOS UNK ? EOS UNK ? EOS UNK ?\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "encoder = encoder.to(\"cpu\")\n",
    "decoder = decoder.to(\"cpu\")\n",
    "\n",
    "def evaluate(sentence, T=1.0):\n",
    "    encoded = sentence2idx(sentence, eng2idx)\n",
    "    output = []\n",
    "    print(encoded)\n",
    "    print(sentence)\n",
    "    bs = 10\n",
    "    with torch.no_grad():\n",
    "      \n",
    "        z = torch.LongTensor(encoded).view(1, -1).repeat(bs, 1)\n",
    "        \n",
    "        def decode_inference(initial_state, batch_size, max_len):\n",
    "            batch_size = len(initial_state[0])\n",
    "            state = initial_state\n",
    "\n",
    "            # We generate SOS at first\n",
    "            outputs = [torch.full([batch_size], rus2idx['SOS'], dtype=torch.int64, \n",
    "                                  device='cpu')]\n",
    "            all_states = [initial_state]\n",
    "\n",
    "            for i in range(max_len):\n",
    "                state, logits = decoder.decode_step(state, outputs[-1])\n",
    "                logits = nn.Softmax(dim=-1)(logits / T)\n",
    "                logits_np = logits.detach().cpu().numpy()\n",
    "                logits = torch.full([batch_size], 0)\n",
    "                \n",
    "                for j in range(batch_size):\n",
    "                    probs = logits_np[j]\n",
    "                    idx = np.random.choice(len(probs), p=probs)\n",
    "                    logits[j] = idx\n",
    "                    \n",
    "                outputs.append(logits)\n",
    "                all_states.append(state)\n",
    "\n",
    "            return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "        hid = encoder.init_hidden(batch_size=bs).to(device='cpu')\n",
    "        initial_state = encoder(z, hid)\n",
    "        out_ids, states = decode_inference(initial_state, bs, 15)\n",
    "        output = out_ids.cpu().numpy()\n",
    "        \n",
    "        for s in output:\n",
    "            out = idx2sentence(s, idx2rus)\n",
    "            print(out.replace('PAD', \"\"))\n",
    "        \n",
    "\n",
    "    \n",
    "evaluate(\"What is going on?\", T = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "se6kfd5dn1ijt60i3emas",
    "execution_id": "091e91c1-9798-4b33-9ca6-ebe3830f8434"
   },
   "source": [
    "Как видим при маленькой температуре мы получаем строго одно и то же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "cellId": "0hih5ffzyropi8gk0vgiw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 23, 14, 63, 46, 9, 2]\n",
      "What is going on?\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS UNK\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "evaluate(\"What is going on?\", T = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dtzq6m3bcm47eekyc3als",
    "execution_id": "73e50c28-562e-45b0-a622-05917663c544"
   },
   "source": [
    "При большой температура - разнообразные сэмплы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "cellId": "ul4zb485mtplj2cda1c7p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 23, 14, 63, 46, 9, 2]\n",
      "What is going on?\n",
      "SOS что происходит UNK ? EOS том UNK ? EOS EOS EOS UNK ? UNK ?\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS вздохнул UNK ? EOS\n",
      "SOS что ходить у вас UNK ? EOS UNK ? EOS UNK ? EOS UNK ?\n",
      "SOS что вы собираетесь преступник UNK ? EOS моя UNK ? EOS дурак UNK ? EOS\n",
      "SOS почему насчет тома UNK ? EOS преступник UNK ? EOS UNK ? EOS EOS UNK\n",
      "SOS что происходит в одиночку UNK ? EOS UNK ? EOS UNK ? EOS отменить UNK\n",
      "SOS что происходит UNK ? EOS UNK ? EOS UNK ? EOS EOS UNK ? EOS\n",
      "SOS какои еду поидете UNK ? EOS UNK ? EOS UNK ? EOS UNK ? EOS\n",
      "SOS что том тут UNK UNK ? EOS полотенце EOS EOS UNK ? EOS UNK ?\n",
      "SOS что происходит UNK ? EOS UNK ? в EOS зоопарке UNK ? EOS UNK ?\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "evaluate(\"What is going on?\", T = 1.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "1c3a9360-9afe-45df-a90b-007ca84f4520",
  "notebookPath": "oganyan_hw1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
