{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1IMoqFPZ-_E"
      },
      "source": [
        "\n",
        "The task of decrypting a message using RNN.\n",
        "You are given messages encrypted with a Caesar cipher, which is one of the simplest ciphers in cryptography.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YNGZnxua61K"
      },
      "source": [
        "The Caesar cipher works like this: each letter\n",
        "of the original alphabet is shifted by K characters to the right:\n",
        "\n",
        "Let us be given a message: message=\"RNN IS NOT AI\", then our encryption performed according to the rule f, with K=2, will give us the result:\n",
        "f(message, K) = TPPAKUAPQVACK\n",
        "\n",
        "For convenience, we can say that all letters of a non-English alphabet will be marked as a dash \"-\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPH9sAiDe77A"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoZVmCuEdO7Y"
      },
      "source": [
        "# Define key and vocabular\n",
        "key = 2\n",
        "vocab = [char for char in ' -ABCDEFGHIJKLMNOPQRSTUVWXYZ']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAsJDtSsGgOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d423e78b-ce8a-4fcd-b700-3b8e2612d4cf"
      },
      "source": [
        "def encrypt(text, key):\n",
        "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
        "    indexes = [vocab.index(char) for char in text]\n",
        "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
        "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
        "    encrypted = ''.join(encrypted_chars)\n",
        "    return encrypted\n",
        "\n",
        "print(encrypt('RNN IS NOT AI', key))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPPAKUAPQVACK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6QNnDJPdxXC"
      },
      "source": [
        "Now we need to generate a dataset for solving the supervised learning problem. Our dataset can be randomly encrypted phrases, and then its structure will be as follows:\n",
        "message --- encrypted message\n",
        "\n",
        "This is an example of a parallel corpus from NLP.\n",
        "\n",
        "But we need to represent each letter as its number in the dictionary in order to use the Embedding layer further.\n",
        "\n",
        "For simplicity, let's assume that all strings have the same *seq_len* length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te9ugR1AIjEw"
      },
      "source": [
        "num_examples = 256 # dataset size\n",
        "seq_len = 18 \n",
        "\n",
        "\n",
        "def encrypted_dataset(dataset_len, k):\n",
        "    \"\"\"\n",
        "    Return: List(Tuple(Tensor encrypted, Tensor source))\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    for x in range(dataset_len):\n",
        "        random_message  = ''.join([random.choice(vocab) for x in range(seq_len)])\n",
        "        encrypt_random_message = encrypt(''.join(random_message), k)\n",
        "        src = [vocab.index(x) for x in random_message]\n",
        "        tgt = [vocab.index(x) for x in encrypt_random_message]\n",
        "        dataset.append([torch.tensor(tgt), torch.tensor(src)])\n",
        "    return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RUxQqTCGUtx"
      },
      "source": [
        "**Pytorch RNN:**\n",
        "$$h_t = \\text{tanh}(w_{ih} x_t + b_{ih} + w_{hh} h_{(t-1)} + b_{hh})$$\n",
        "\n",
        "**where : $h_t$ is the hidden state at time $t$, $x_t$ is\n",
        "    the input at time $t$, and $h_{(t-1)}$ is the hidden state of the\n",
        "    previous layer at time $t-1$ or the initial hidden state at time $0$.**\n",
        "    \n",
        "Args: \n",
        "\n",
        "        input_size: The number of expected features in the input $x$\n",
        "        hidden_size: The number of features in the hidden state $h$\n",
        "        num_layers: Number of recurrent layers. E.g., setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03y7VB9QLorQ"
      },
      "source": [
        "class Decipher(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
        "                 rnn_type='simple'):\n",
        "        \"\"\"\n",
        "        :params: int vocab_size \n",
        "        :params: int embedding_dim\n",
        "        :params\n",
        "        \"\"\"\n",
        "        super(Decipher, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if rnn_type == 'simple':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers = 2)\n",
        "         \n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.initial_hidden = torch.zeros(2, 1, hidden_dim)\n",
        "\n",
        "        \n",
        "    def forward(self, cipher):\n",
        "        # CHECK INPUT SIZE\n",
        "        # Unsqueeze 1 dimension for batches\n",
        "        embd_x = self.embed(cipher).unsqueeze(1)\n",
        "        out_rnn, hidden = self.rnn(embd_x, self.initial_hidden)\n",
        "        # Apply the affine transform and transpose output in appropriate way\n",
        "        # because you want to get the softmax on vocabulary dimension\n",
        "        # in order to get probability of every letter\n",
        "        return self.fc(out_rnn).transpose(1, 2)\n",
        "      "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rnb-2qIIjM7"
      },
      "source": [
        "# set model parameters\n",
        "embedding_dim = 5\n",
        "hidden_dim = 10\n",
        "vocab_size = len(vocab) \n",
        "lr = 1e-3\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize model\n",
        "model = Decipher(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "# Initialize optimizer: Adam is recommended\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "num_epochs = 10"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZO1uR7fIjQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e5f245-f0a1-4ff1-f3f8-a59cb5d2e9bd"
      },
      "source": [
        "k = 10\n",
        "for x in range(num_epochs):\n",
        "    print('Epoch: {}'.format(x))\n",
        "    for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "\n",
        "        scores = model(encrypted)\n",
        "        original = original.unsqueeze(1)\n",
        "        # Calculate loss\n",
        "        loss = criterion(scores, original)\n",
        "        # Zero grads\n",
        "        optimizer.zero_grad()\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "    print('Loss: {:6.4f}'.format(loss.item()))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        matches, total = 0, 0\n",
        "        for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "            # Compute a softmax over the outputs\n",
        "            predictions = F.softmax(model(encrypted), 1)\n",
        "            # Choose the character with the maximum probability (greedy decoding)\n",
        "            _, batch_out = predictions.max(dim=1)\n",
        "            # Remove batch\n",
        "            batch_out = batch_out.squeeze(1)\n",
        "            # Calculate accuracy\n",
        "            matches += torch.eq(batch_out, original).sum().item()\n",
        "            total += torch.numel(batch_out)\n",
        "        accuracy = matches / total\n",
        "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Loss: 2.5849\n",
            "Accuracy: 30.97%\n",
            "Epoch: 1\n",
            "Loss: 1.8316\n",
            "Accuracy: 70.72%\n",
            "Epoch: 2\n",
            "Loss: 1.3102\n",
            "Accuracy: 89.80%\n",
            "Epoch: 3\n",
            "Loss: 0.8673\n",
            "Accuracy: 98.61%\n",
            "Epoch: 4\n",
            "Loss: 0.5550\n",
            "Accuracy: 100.00%\n",
            "Epoch: 5\n",
            "Loss: 0.4002\n",
            "Accuracy: 100.00%\n",
            "Epoch: 6\n",
            "Loss: 0.3031\n",
            "Accuracy: 100.00%\n",
            "Epoch: 7\n",
            "Loss: 0.2130\n",
            "Accuracy: 100.00%\n",
            "Epoch: 8\n",
            "Loss: 0.1517\n",
            "Accuracy: 100.00%\n",
            "Epoch: 9\n",
            "Loss: 0.1405\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqPb89PFBeof"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}