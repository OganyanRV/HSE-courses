{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBeojQNTzwY-"
      },
      "source": [
        "\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Homework. PyTorch and Fully Connected Networks</b></h3>\n",
        "\n",
        "You will practice building neural networks using the Pytorch library on several datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd-KUTc1CBXm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "sns.set(style=\"darkgrid\", font_scale=1.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvKrWYan4Rxr"
      },
      "source": [
        "# Part 1. Moons dataset\n",
        "\n",
        "Let's generate a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3nwjSJFUP7"
      },
      "source": [
        "X, y = make_moons(n_samples=10000, random_state=42, noise=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa9UCvRyJFqL"
      },
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title(\"Dataset\")\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6BcB14d4wGm"
      },
      "source": [
        "Train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv5MyTiCHjRh"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTeLXQg240cQ"
      },
      "source": [
        "### Data loading\n",
        "In PyTorch, two entities `Dataset` and `DataLoader` are used for data loading.\n",
        "\n",
        "1. `Dataset` loads each object individually.\n",
        "\n",
        "2. `DataLoader` groups objects from `Dataset` into batches.\n",
        "\n",
        "Since our dataset is quite small we will use `TensorDataset`. All we need is to convert from a numpy array to a tensor with type `torch.float32`.\n",
        "\n",
        "### Exercise (0.5 points). Create tensors with train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msj3bXOeIcN-"
      },
      "source": [
        "X_train_t =  # YOUR CODE GOES HERE\n",
        "y_train_t =  # YOUR CODE GOES HERE\n",
        "X_val_t =  # YOUR CODE GOES HERE\n",
        "y_val_t =  # YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqwGMsE_7WBy"
      },
      "source": [
        "Create `Dataset` Ð¸ `DataLoader`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERvubjbMIu2J"
      },
      "source": [
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKyYQcec7cu4"
      },
      "source": [
        "### Exercise (1 point). Implementing Logistic Regression\n",
        "\n",
        "You need to write a PyTorch module that implements $logits = XW + b$, where $W$ and $b$ are parameters (`nn.Parameter`) of the model. In other words, here we implement the `nn.Linear` module ourselves (in this exercise, its use is prohibited). Initialize the weights with a normal distribution (`torch.randn`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U1y-0KtCTne"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn)\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.bias_term = # YOUR CODE GOES HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  # YOUR CODE GOES HERE\n",
        "        if self.bias:\n",
        "            x +=  # YOUR CODE GOES HERE\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIgTLHSM-10"
      },
      "source": [
        "linear_regression = LinearRegression(2, 1)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(linear_regression.parameters(), lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NV-JrNCoP8E"
      },
      "source": [
        "### Train loop\n",
        "\n",
        "Here is a pseudocode to help you figure out what's going on during training\n",
        "\n",
        "```python\n",
        "for epoch in range(max_epochs):  # <----------- iterate over the dataset several times\n",
        "    for x_batch, y_batch in dataset:  # <------ iterate over the dataset. Since we use SGD and not GD, we take batches of a given size\n",
        "        optimizer.zero_grad()  # <------------- reset model gradients\n",
        "        outp = model(x_batch)  # <------------- get \"logits\" from the model\n",
        "        loss = loss_func(outp, y_batch)  # <--- calculate \"loss\" for logistic regression\n",
        "        loss.backward()  # <------------------- find gradients\n",
        "        optimizer.step()  # <------------------ do the gradient descent step\n",
        "        if convergence:  # <------------------- in case of convergence exit the cycle\n",
        "            break\n",
        "```\n",
        "\n",
        "In the code below `accuracy` and `loss` logging was added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1DvfCPY7TMZ"
      },
      "source": [
        "### Exercise (1 point). Implementation of the training cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVhlIfK0L93s"
      },
      "source": [
        "tol = 1e-3\n",
        "losses = []\n",
        "max_epochs = 100\n",
        "prev_weights = torch.zeros_like(linear_regression.weights)\n",
        "stop_it = False\n",
        "for epoch in range(max_epochs):\n",
        "    for it, (X_batch, y_batch) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outp =  # YOUR CODE. Use linear_regression to get outputs\n",
        "        loss =  # YOUR CODE. Compute loss\n",
        "        loss.backward()\n",
        "        losses.append(loss.detach().flatten()[0])\n",
        "        optimizer.step()\n",
        "        probabilities =  # YOUR CODE. Compute probabilities\n",
        "        preds = (probabilities > 0.5).type(torch.long)\n",
        "        batch_acc = (preds.flatten() == y_batch).type(torch.float32).sum() / y_batch.size(0)\n",
        "        \n",
        "        if (it + epoch * len(train_dataloader)) % 100 == 0:\n",
        "            print(f\"Iteration: {it + epoch * len(train_dataloader)}\\nBatch accuracy: {batch_acc}\")\n",
        "        current_weights = linear_regression.weights.detach().clone()\n",
        "        if (prev_weights - current_weights).abs().max() < tol:\n",
        "            print(f\"\\nIteration: {it + epoch * len(train_dataloader)}.Convergence. Stopping iterations.\")\n",
        "            stop_it = True\n",
        "            break\n",
        "        prev_weights = current_weights\n",
        "    if stop_it:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBJ64-MT63_r"
      },
      "source": [
        "**Question (0.33 points).** How many iterations did it take for the algorithm to converge?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As-pgFbzFmiI"
      },
      "source": [
        "### Visualize the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzPRB8j4b1IF"
      },
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(range(len(losses)), losses)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cGgcBMNX2WP"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "xx, yy = np.mgrid[-1.5:2.5:.01, -1.:1.5:.01]\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "batch = torch.from_numpy(grid).type(torch.float32)\n",
        "with torch.no_grad():\n",
        "    probs = torch.sigmoid(linear_regression(batch).reshape(xx.shape))\n",
        "    probs = probs.numpy().reshape(xx.shape)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(16, 10))\n",
        "ax.set_title(\"Decision boundary\", fontsize=14)\n",
        "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
        "                      vmin=0, vmax=1)\n",
        "ax_c = f.colorbar(contour)\n",
        "ax_c.set_label(\"$P(y = 1)$\")\n",
        "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
        "\n",
        "ax.scatter(X[100:,0], X[100:, 1], c=y[100:], s=50,\n",
        "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
        "           edgecolor=\"white\", linewidth=1)\n",
        "\n",
        "ax.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9G-UkrE-Arr"
      },
      "source": [
        "### Exercise (1 point). Implement predict and calculate accuracy on test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP_imFpe7Ac4"
      },
      "source": [
        "@torch.no_grad()\n",
        "def predict(dataloader, model):\n",
        "    model.eval()\n",
        "    predictions = np.array([])\n",
        "    for x_batch, _ in dataloader:\n",
        "        <YOUR CODE>\n",
        "        preds = #YOUR CODE. Compute predictions\n",
        "        predictions = np.hstack((predictions, preds.numpy().flatten()))\n",
        "    return predictions.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0vaJdAS7Dfq"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# YOUR CODE. Compute total accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7TXs3kk7Kmq"
      },
      "source": [
        "**Question (0.33 points)**\n",
        "\n",
        "What `accuracy` is obtained after training?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyivMZBZC0Ha"
      },
      "source": [
        "# Part 2. MNIST Dataset\n",
        "The MNIST dataset contains handwritten numbers. Let's load the dataset and create DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuUE2wihC4GW"
      },
      "source": [
        "import os\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "data_tfs = tfs.Compose([\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "# install for train and test\n",
        "root = './'\n",
        "train_dataset = MNIST(root, train=True,  transform=data_tfs, download=True)\n",
        "val_dataset  = MNIST(root, train=False, transform=data_tfs, download=True)\n",
        "\n",
        "train_dataloader =  # YOUR CODE GOES HERE\n",
        "valid_dataloader =  # YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t2w2XtSB1Hd"
      },
      "source": [
        "## Part 2.1. Fully Connected Neural Networks\n",
        "We start with a fully connected neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvcy_wYFh1Lv"
      },
      "source": [
        "class Identical(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMtCBdCA-4bj"
      },
      "source": [
        "### Exercise (1 point). Simple fully connected neural network\n",
        "\n",
        "Create a fully connected neural network using the Sequential class. The network consists of:\n",
        "* Flattening a matrix into a vector (nn.Flatten);\n",
        "* Two hidden layers of 128 neurons with nn.ELU activation;\n",
        "* Output layer with 10 neurons.\n",
        "\n",
        "Set the training loss (cross-entropy).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxWHddEiQCr"
      },
      "source": [
        "activation = nn.ELU\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    #YOUR CODE. Add layers to your sequential class\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIl6z-AfivcK"
      },
      "source": [
        "criterion = #YOUR CODE. Select a loss function\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whvqhLjYmpKc"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xl_HawRGRAe"
      },
      "source": [
        "### Train loop\n",
        "\n",
        "The code below will work for 80% of tasks you can face.\n",
        "\n",
        "```python\n",
        "for epoch in range(max_epochs):  # <--------------- iterate over the dataset several times\n",
        "    for k, dataloader in loaders.items():  # <----- several dataloaders for train/valid/test\n",
        "        for x_batch, y_batch in dataloader:  # <--- iterate over the dataset. Since we use SGD and not GD, we take batches of a given size\n",
        "            if k == \"train\":\n",
        "                model.train()  # <------------------ put the model into train mode\n",
        "                optimizer.zero_grad()  # <--------- reset model gradients\n",
        "                outp = model(x_batch)\n",
        "                loss = criterion(outp, y_batch) # <-calculate \"loss\" for logistic regression\n",
        "                loss.backward()  # <--------------- find gradients\n",
        "                optimizer.step()  # <-------------- do the gradient descent step\n",
        "            else:  # <----------------------------- test/eval\n",
        "                model.eval()  # <------------------ put the model in eval mode\n",
        "                with torch.no_grad():  # <--------- DO NOT find gradients\n",
        "                    outp = model(x_batch)  # <------------- get \"logits\" from the model\n",
        "            count_metrics(outp, y_batch)  # <-------------- find metrics\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raKQWwQm_9Ff"
      },
      "source": [
        "### Exercise (1.5 points). Complete the learning cycle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tmo1lsHjBE6"
      },
      "source": [
        "max_epochs = 10\n",
        "accuracy = {\"train\": [], \"valid\": []}\n",
        "for epoch in range(max_epochs):\n",
        "    for k, dataloader in loaders.items():\n",
        "        epoch_correct = 0\n",
        "        epoch_all = 0\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            if k == \"train\":\n",
        "                 # YOUR CODE. Set model to ``train`` mode and calculate outputs. Don't forget zero_grad!\n",
        "            else:\n",
        "                 # YOUR CODE. Set model to ``eval`` mode and calculate outputs\n",
        "            preds = outp.argmax(-1)\n",
        "            correct =  # YOUR CODE GOES HERE\n",
        "            all =  # YOUR CODE GOES HERE\n",
        "            epoch_correct += correct.item()\n",
        "            epoch_all += all\n",
        "            if k == \"train\":\n",
        "                loss = criterion(outp, y_batch)\n",
        "                # YOUR CODE. Calculate gradients and make a step of your optimizer\n",
        "        if k == \"train\":\n",
        "            print(f\"Epoch: {epoch+1}\")\n",
        "        print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n",
        "        accuracy[k].append(epoch_correct/epoch_all)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFRxO1-FK9U9"
      },
      "source": [
        "### Exercise (1.5 points). Different activation functions.\n",
        "Try different activation functions. For each activation function, count the validation accuracy array. It is better to implement this as a function that takes an activation as input and receives an array of accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SezseDhEqhm2"
      },
      "source": [
        "elu_accuracy = accuracy[\"valid\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSVBlHtuAUAh"
      },
      "source": [
        "# YOUR CODE. Do the same thing with other activations (it's better to wrap into a function that returns a list of accuracies)\n",
        "\n",
        "def test_activation_function(activation):\n",
        "    #YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1iXow0Tqsri"
      },
      "source": [
        "plain_accuracy = test_activation_function(Identical)\n",
        "relu_accuracy = #YOUR CODE\n",
        "leaky_relu_accuracy = #YOUR CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK07mms3FwNd"
      },
      "source": [
        "### Accuracy\n",
        "Let's plot an accuracy/epoch graph for each activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvKclpM5r-P3"
      },
      "source": [
        "sns.set(style=\"darkgrid\", font_scale=1.4)\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "plt.title(\"Valid accuracy\")\n",
        "plt.plot(range(max_epochs), plain_accuracy, label=\"No activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R8L1JCts_qz"
      },
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title(\"Valid accuracy\")\n",
        "plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), leaky_relu_accuracy, label=\"LeakyReLU activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl8qYSSa7c-r"
      },
      "source": [
        "**Question. (0.33 points)** Which of the activation functions showed the highest `accuracy` by the end of the training?\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8fcWWSFCfHpj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}